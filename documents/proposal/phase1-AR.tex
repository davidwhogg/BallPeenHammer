%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%    phase1-AR.tex  (use only for Archival Research and Theory proposals; 
%                     use phase1-GO.tex for General Observer and Snapshot
%                     proposals and phase1-DD.tex for GO/DD proposals).
%
%    HUBBLE SPACE TELESCOPE
%    PHASE I ARCHIVAL & THEORETICAL RESEARCH PROPOSAL TEMPLATE 
%    FOR CYCLE 21 (2013)
%
%    Version 1.0, December  1, 2012.
%
%    Guidelines and assistance
%    =========================
%     Cycle 21 Announcement Web Page:
%
%         http://www.stsci.edu/hst/proposing/docs/cycle21announce 
%
%    Please contact the STScI Help Desk if you need assistance with any
%    aspect of proposing for and using HST. Either send e-mail to
%    help@stsci.edu, or call 1-800-544-8125; from outside the United
%    States, call [1] 410-338-1082.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% The template begins here. Please do not modify the font size from 12 point.

\documentclass[12pt]{article}
\usepackage{phase1,hyperref,graphicx,color}

\newcommand{\documentname}{\textsl{AR Proposal}}
\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\HST}{\project{HST}}
\newcommand{\WFC}{\project{WFC3}}
\newcommand{\MAST}{\project{MAST}}
\newcommand{\dd}{\mathrm{d}}

\newcommand{\bvec}[1]{\textbf{\textit{#1}}}

\begin{document}

%   1. SCIENTIFIC JUSTIFICATION
%       (see Section 9.1 of the Call for Proposals)
%
%
\justification          % Do not delete this command.

With weak lensing surveys, high-redshift galaxy science, and exoplanet
discovery and characterization, the requirements on imaging
calibration are becoming extremely severe.  At the same time,
next-generation projects like \project{JWST}, \project{Euclid}, and
\project{WFIRST} are being designed with very strong budget and
observing-time pressure on calibration programs: We want as much of
the data in ``science'' mode as possible.  One paradox of calibration
programs is that although they incur significant operational overheads
(especially for projects like \project{Euclid} performing large
solid-angle surveys with strict cadence requirements), it is
nonetheless the case the vast majority of the \emph{photons} detected
by the infrared detectors will be detected in the science frames, not
the calibration frames.  The science frames themselves therefore
contain enormous stores of information about calibration.  Unlocking
this information is the goal of the group of methods known as
\emph{self-calibration}.  In this \documentname, we propose to develop
a completely new kind of self-calibration that has the potential to
deliver precise, fine-scale imaging calibration.  We propose to apply
the new methods to the entire body of \WFC\ IR-channel data available
in \MAST.  Our deliverables will be new \WFC\ flat-field maps and the
code that generated them.

Precise calibration of the detector in an astronomical imaging camera
is not trivial---and it is only harder if it is in space.
Fundamentally, the sensitivity of the device must be calibrated with
incident photons; no artificial light source is available; even if an
artificial source \emph{were} available, it could not be designed to
illuminate the device exactly as does a star or other astronomical
source.

The imaging devices of \HST\ (and specifically \WFC) are calibrated by a number of
methods:
\\ $\bullet$ \project{laboratory calibration}: The instrument was illuminated
  in the laboratory pre-flight (\href{http://bit.ly/Xn8OOH}{ISR WFC3
    2008-28}).  In principle this calibration can be
  done perfectly, but \textsl{(a)}~usually the calibration
  illumination does not illuminate the instrument exactly as does an
  in-flight star observation, and \textsl{(b)}~usually the light
  source does not have a completely appropriate SED.  The laboratory
  calibration happens pre-launch, so changes in the instrument through
  launch and in flight cannot be captured, nor can some aspects of in-launch
  environment (loading, temperature, pressure).
\\ $\bullet$ \project{standard stars}: On a regular schedule, well-understood
  standard stars are placed in the instrument focal plane to test the
  on-orbit throughput of the device (e.g.,
  \href{http://bit.ly/Y7wx5v}{ISR WFC3 2009-05}).  These
  observations are key to instrument monitoring, but they don't
  calibrate the device at the pixel level; they provide only overall
  throughput measurements.
\\ $\bullet$ \project{grid test}: The throughput measurements are transferred
  out to the entire device by grid tests, in which standards or a star
  field are stepped over the instrument focal plane (e.g., \href{http://bit.ly/XFdEYW}{ISR WFC3
  2009-39}).  This brings the same astronomical source to many
  different focal-plane positions; it permits relative calibration of
  different parts of the detector. The grid, however, is not dense at
  the pixel level.  The grid test does not provide a pixel-to-pixel
  flat field; it only calibrates the flat on large scales.
\\ $\bullet$ \project{super-flat}: The only in-flight source of
  pixel-to-pixel sensitivity information are the photons detected in
  the sky---the blank parts of the imaging.  These photons can be
  combined (with masking of detected astronomical sources) into a
  pixel-level sensitivity map (\href{http://bit.ly/YJJB2m}{ISR
    WFC3-2011-11}).  Unfortunately, this
  map is a sensitivity to the \emph{sky} not to a \emph{star}: The sky
  has a different SED than any star.  More importantly, the
  uniform-brightness sky illuminates the device differently than any
  star.  This problem is a bigger problem for open-structure
  ground-based telescopes than it is for \HST, but it isn't known to
  be negligible for \HST.  

There is no method---not even any \emph{combination of methods}---that
can be used to do all of \textsl{(1)}~test the calibration of the
detector in-flight, \textsl{(2)}~provide information on pixel-to-pixel
relative sensitivity (small scales), \textsl{(3)}~illuminate the
detector as stars do, and \textsl{(4)}~illuminate with the SED or
color of astronomical sources of interest.  It is possible that these
things don't matter---that every pixel of every \HST\ instrument is
properly calibrated---but it is close to impossible to know with the
calibration data available at present.  That is, if the flat
appropriate to stellar sources is different at fine (pixel-level)
angular scales from the flat appropriate to sky photons, that problem
would not appear strongly in current calibration data.

\textbf{Here we propose to calibrate the \WFC\ IR channel at the pixel
  level using all of the F110W and F160W science data availble in \MAST.}
Importantly, we will build this calibration from the astronomical
sources in the data, \emph{not} the blank-sky parts of the imaging.
By construction, the flats we produce will be built from sources with
astrophysically relevant SEDs.

In general there are two approaches for self-calibration of this kind.
The first---what we might call ``traditional'' self-calibration---is
built on the principle that if the \emph{same object} is observed at
\emph{different focal-plane positions} the inferences made ought to be
independent of focal-plane position.  This kind of self-calibration is
most effective when the observatory obeys calibration-oriented
observing strategies (\href{http://bit.ly/15TAoYy}{Holmes et
  al. 2012}), and those strategies involve
multiple observations for most sources.  The simplest kind of
self-calibration is the ``grid test'' mentioned above.  The most
ambitious self-calibration was that performed (by the PI and
collaborators) with the entire point-source catalog of the
\project{Sloan Digital Sky Survey}
(\href{http://bit.ly/12dPkSh}{Padmanabhan et al. 2008}).  Traditional
self-calibration (beyond the grid test) is not applicable to most
\HST\ instruments, because sources are rarely observed multiple times,
and when they are it is usually on one of a small number of
small-angle dithers.  Good self-calibration requires a large diversity
of large-angle dithers (\href{http://bit.ly/15TAoYy}{Holmes et al. 2012}).

In the second approach---what we might call ``probabilistic''
self-calibration---the fundamental principle is that no \emph{pixel}
will see a \emph{special set of astronomical objects}.  (Of course
this assumption is wrong in important ways, to which we will return
below.\footnote{\color{red} DWH: We must return to these below!})  This kind of
self-calibration is applicable in (almost) any observing strategy,
provided that the imager has been used to make \emph{an large
  number of observations}.

In a probabilistic self-calibration, the idea is that any patch of any
image from any exposure in any region of the focal plane ought to be
possible to generate from some kind of reasonable astronomical
``scene'' convolved with the known point-spread function.  Aside from
the differences generated by the variation of the PSF over the
field-of-view, the distribution of possible image patches ought to be
the same in all parts of the device.  In other words, every small
(calibrated) image patch---when the device is properly
calibrated---must display a (very tiny) scene that \emph{could
  possibly be observed} by \HST.  If the calibration parameters get
set to bad values, the observed image patches will contain imprints of
the calibration errors, related to the location on the focal plane
from which they are taken.  The simplest version of probabilistic
self-calibration is the construction of the ``super-flat'' in the
current \WFC\ calibration strategy; the super-flat is constructed by
forcing statistics of the pixel values to be constant across the
device.  The most extreme version of probabilistic self-calibration
would be to construct highly informative prior PDFs for astronomical
scenes and find the calibration parameters (and PSF parameters,
perhaps) at which the output images match best those priors!  Here we
propose to do something intermediate, much more ambitious and
informative than the super-flat, but tractable with current \WFC\ data
and computation.


\begin{flushleft} 
\href{http://bit.ly/15TAoYy}{Holmes, R., et al., 2012, PASP, 124,
  1219} \newline
\href{http://bit.ly/12dPkSh}{Padmanabhan, N., et al., 2008, ApJ, 674, 1217}
\end{flushleft}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   2. ANALYSIS PLAN
%       (see Section 9.6 of the Call for Proposals)
%
%
\describearchival       % Do not delete this command.
% Enter your analysis plan here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\color{red} \textbf{We must include in `analysis plan', section 9.6 in Call -} 
i) Details of analysis and datasets to be analyzed.  ii) do APT
checklist iii) schedule for data delivery (is this in APT?) iv) what
docs, data products, and software will we deliver? v) how does this 
complement ongoing calib efforts?}

The goal of our archival analysis is to perform probabilistic
self-calibration of WFC3 IR data.  Such aims can be very broad,
encompassing a range of calibration problems including static or slowly 
evolving issues (e.g., object and sky flat fields, ...) or transient
issues (e.g., persistence, `snow balls', ...).  Since our approach is
new and some-what exploratory, our analysis plan is to first focus on
achievable a baseline project, taking advantage of much of the current
knowledge of WFC3 (e.g., PSF model), and subsequently focusing on
enhanced-level deliverables.

\textbf{Our baseline goal is to produce a new, pixel-to-pixel
  flat field model for the WFC3 F110W and F160W filters.}
Fundamentally, our method relies on the fact
that stars observed by HST are point sources, convolved by the PSF at
the location on the detector.  Beyond a simple normalization,
therefore, all stars ought to look similar if 1) the PSF (as a
function of time and position) is well understood, and 2) the
pixel-to-pixel calibration of the instrument is correct.  If, however,
a there is a pixel level error in the flat field, stars whos flux
touches the poorly calibrated pixel will look quite different when
compared to the flux distributions of all the other stars.  

More technically, we intend to build a pixel-level, generative model
for the data, under the best current PSF model for WFC3.  We begin by
taking all $M$ images for a filter, and dividing up the images into
small patches $D_n$ ($5 \times 5$ pixels), $N$ of which contain significant
flux from a source.  Here, our baseline approach assumes everything in
the \textsl{calwfc3} pipeline to be true, except for the flat field
which we will infer.  Therefore, the $D_n$ patchs are taken from
\texttt{flt} files which have had no flat applied.  Our model for a
patch is 

\begin{eqnarray}
D_n & = & F \cdot (S_n \otimes \Psi_n) + \epsilon_n + H
\quad .
\end{eqnarray}

In short, we model the patch $D_n$ as an underlying astronomical scene
$S_n$ (flux located at a delta function in space for stars, surface
brightness distribution for galaxies) convolved with the pixelated
PSF.  Note that the model for $S_n$ will have a centroid outside the
patch in the vast majority of patches.  The convolved scene is
mulitiplied by the pixelated flat field
model model, and has additive noise $\epsilon_n$.  Additionally, we
can image higher order effects $H$ not covered by our flat field and
\textsl{calwfc3}, like persistence.  For our baseline we will mask or
ignore such terms, but will return to these issues as enhanced goals
(see below).  Additionally, our baseline project will assume a PSF
model across the detector, from observations of bright stars (e.g.,
\href{http://bit.ly/XFSb1M}{ISR WFC3 2009-37}).  Note the patch $D_n$
has associated metadata (like time, temperature, and location on the
detector).  We will use this to identify the correct portion of the
current flat field model, as well as the correct PSF and noise model
(since, e.g., the PSF is known to vary over time and location).  

A critical part of this model involves knowing the the underlying
scene that comprises $S_n$, which can often be quite complicated.  For
this reason, we plan to restrict the $N$ total patches to those whose
scenes are well fit by either one or two stars, or a single compact
galaxy (who is well fit by a S\'{e}rsic profile).  After determining
the patches to use for calibration, we can determine the flat field
using standard interference machinary:

\begin{eqnarray}
p(D_n|F,S_n,\epsilon_n) &=& N(F \cdot (S_n \otimes \Psi_n), \epsilon_n^2)
\\
p(\bvec{D}|F,{\bf S},{\bf \Psi},{\bf \epsilon}) &=& \prod_n^N
p(D_n|F,S_n,\epsilon_n) \\
p(F|\bvec{D},{\bf \epsilon}) & \propto & p(\bvec{D}|F,{\bf S},{\bf \Psi},{\bf
  \epsilon}) p(F) p({\bf S}) p({\bf \Psi})
\quad .
\end{eqnarray}

Here, we treat the likelihood for individual patches as Gaussian, under the
noise model determined by \textsl{calwfc3} and the total likelihood is
just the product over all patches. The posterior probability of the
flat field involves specifying priors over \textsl{(1)} the flat
field, which we will take to be the \textsl{calwfc3} LP flats with
known uncertainty, \textsl{(2)} a prior over scenes ${\bf S}$, which
is specified during our fitting procedure, and \textsl{(3)} the PSF
which we will assign as mentioned above, but with some uncertainty.

We plan to deliver (for our baseline) the pixel-to-pixel flat
fields (and software that produces them) for the F110W and F160W
filters.  We are choosing these particular filters since they are
amongst the most heavily used with WFC3 IR observations, having taken
1626 and 4149 exposures\footnote{As of Feb. 27, 2013.} longer than
100s, respectively.  In addition, we choose these filters
since they provide a set of tests with which we can assess the
fidelity of our flat fields.  Specifically, we will first examine the
consistency of the photometry of standard stars (gridded across 
the detector).  Subsequently, Jason Kalirai has volunteered to
reprocess WFC3 observations of 47 Tuc (see Kalirai et al. 2012), for
which we can examine the consistency of the Main Sequence of the
cluster.  In both cases, photometry will be performed on the
individual dithers, rather than the drizzled images (which may
introduce scatter, depending on the procedure).  By comparing the
results from our flat fields to those using standard \emph{calwfc3}
flats (as well as the flat fields themselves), \emph{we will produce
  the first verification of the pixel level flat field since the
  launch of WFC3}.  Beyond this zero-th result from our baseline
project, we expect we will learn new ways in which the calibration can
be improved, and may possibly provide an improved calibration of the
F110W and F160W filters.  Currently, the uncertainty in the flat
fields are about $0.5\%$, with a peak-to-peak variation of -1.5/1.6\%
(see ISR WFC3-2011-11).  While this is excellent, it will not deliver
the $<1\%$ photometry required by upcoming surveys (e.g., WFIRST,
Euclid).  We therefore view our exploratory archival calibration
project as a worthwhile step forward towards next-generation
calibration techniques.

The above analysis plan we have described is a very simplified, and
achievable set of deliverables that will come out of our archival
research.  However, we intend to explore enhanced project goals which
will tackle increasingly difficult calibration problems. 

%   3. MANAGEMENT PLAN
%       (see Section 9.7 of the Call for Proposals)
%
%  Provide a concise, but complete, management plan. This plan will be used
%  by the review panels to assess the likely scale of the proposed research
%  program. Proposers should include a schedule of the work required to
%  achieve the scientific goals of the program, a description of the roles of the
%  PI, CoIs, postdocs, and students who will perform the work, and a plan to
%  disseminate the results to the community.
%
\budgetnarrative       % Do not delete this command. CALLS the Management Plan header in the Style File (IGNORE the command name of budgetnarrative
% Enter your management plan here.

{\color{red} \textbf{Section 9.7 of Call says -} Provide a concise, but complete, 
management plan. This plan will be used by the review panels to assess 
the likely scale of the proposed research program. Proposers should 
include a schedule of the work required to achieve the scientific
goals of the program, a description of the roles of the PI, CoIs,
postdocs, and students who will perform the analysis, and a plan to 
disseminate the results to the community. }


Prior to this proposal, our team has spent time
developing the some of the tools necessary to execute the above
analysis, and have tested the methods on some toy problems
{\color{red} RF- include this? in total, or just part before comma?}.
Because of this we consider a fairly aggressive timeline to be feasible, in
spite of the ambitious nature of our calibration project.  The timeline will
be to deliver our baseline goals (flat field and code) within 6 months
of beginning the project in earnest.  We envision a rough schedule of
1 month of data collection/familiarization, in parallel with software
development.  Next, roughly 4-5 months of interation and assessment of
the calibration algorithm.  Finally, the last month will involve
finalizing publications and software for release. Enhanced goals will
proceed in the follow $\sim6$ months, depending on results of the
initial study.

The structure of our team is simple.  Co-I Fadely (Postdoc,
NYU) will be responsible for execution - writing the necessary code
and developing the tools needed to produce the results.  PI Hogg
(Physics faculty, NYU) and Co-I Fergus (CS faculty, NYU) will heavily advise,
assess, and consult throughout the project.  Additionally, we intend to
be in touch with the \WFC\, team during the process and have already
discussed (with strong encouragement) our plans with Jason
Kalirai and Susana Deustua at STScI. 

The primary dissemination of our results will come in the form of
refereed publications, and delivering the relevant software to STScI
and the community.  We believe in open science - the code will be open
source, available publically on GitHub.  In addition, we plan to
attend conferences related to (but not restricted to) \HST,
\project{JWST}, \project{LSST}, \project{WFIRST}, and
\project{Euclid}, particularly where discussions of calibration will
be well received.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%   4. PAST HST USAGE
%       (see Section 9.8 of the Call for Proposals)
%
%        List here the program numbers and data status for all accepted GO/AR/SNAP 
%        programs of the PI in at least the last four HST Cycles. Include a list of refereed publications 
%        resulting from these programs.       
%
%       Note that the description of past HST usage  DOES NOT count against the page limits of the proposal.
%
\pasthstusage  % Do not delete this command.

{\color{red} \textbf{This is needed, section 9.8 Call -} List here the program 
numbers and data status for all accepted GO/AR/SNAP programs of the 
PI in at least the last four HST Cycles. Include a list of refereed 
publications resulting from these programs. Calibration Proposals 
should describe what science will be enabled by the successful 
completion of the program, and how the currently supported core 
capabilities, their calibrations, and the existing pipeline or data
reduction software are insufficient to meet the requirements of this 
type of science.}


None of the investigators has an approved \HST\ program in any of the
last four cycles.  That said, PI Hogg has been involved at a data
analysis and consulting level on the large \project{PHAT} project to
image the M31 disk.  This program has generated many refereed papers,
with co-authorship by Hogg only in...  ...Hogg has also been involved
in MARSHALL PROGRAMS?..


% Maybe we dont want figures...  
%
%
%\begin{figure}
%\centering
% \includegraphics[scale=0.35]{pixelvalues_2d.png}
% \includegraphics[scale=0.35]{asym_100.png}
%\caption{An example of the }
%\label{fig:2D}
%\end{figure}



% List here the program numbers and data status for all accepted GO/AR/SNAP
% programs of the PI in at least the last four HST Cycles. Include a list of refereed
% publications resulting from these programs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}          % End of proposal. Do not delete this line.
                                   % Everything after this command is ignored.

